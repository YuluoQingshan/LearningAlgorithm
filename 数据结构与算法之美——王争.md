# 数据结构与算法之美——王争

#### **基础知识就像是一座大楼的地基，它决定了我们的技术高度。而想要快速做出点事情，前提条件一定是基础能力过硬，“内功”要到位。**

#### 基础——操作系统、计算机网络、编译原理、数据结构与算法。

#### 学任何知识都是为了“用”，是为了解决实际工作问题的。

#### **在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。**

#### **掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都非常有用的。你看待问题的深度，解决问题的角度就会完全不一样**。

#### **数据结构是为算法服务的，算法要作用在特定的数据结构之上。**

#### **在学习数据结构和算法的过程中，要学习它的“来历”“自身的特点”“适合解决的问题”以及“实际的应用场景”**

## 一、复杂度分析

#### **复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半。**

### **大** **O** **复杂度表示法**

——**代码执行时间随数据规模增长的变化趋势**

#### 三种方法：

1. #### 只关注循环执行次数最多的一段代码

	大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中 的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，**我们在分析一个算 法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了**。

2. #### 加法法则：总复杂度==量级最大的那段代码的复杂度

3. #### 乘法法则：嵌套代码的复杂度==嵌套内外代码复杂度的乘积



四个复杂度分析方面的知识点，**最好情况时间复杂度**(best case time complexity)、**最坏情况时间复杂度**(worst case time complexity)、**平均情况时间复杂度**(average case time complexity)、**均摊时间复杂度**(amortized time complexity)。如果这几个概念你都能掌握，那对你来说，复杂度分析这部分内容就没什 么大问题了。

#### **最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度**。

#### **最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度**。

#### **平均情况时间复杂度**


最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念:平均情况时间复杂度，简称为**平均时间复杂度**。

很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同
的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。

#### **均摊时间复杂度**


对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。



## 二、数组

### **为什么数组要 从 0 开始编号，而不是从 1 开始呢?**

**数组(Array)是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。**

第一是**线性表**(Linear List)。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。而与它相对立的概念是**非线性表**，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

第二个是**连续的内存空间和相同类型的数据**。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性:“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。

```
数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。
计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。
当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址:
a[i]_address = base_address + i * data_type_size
```

#### 插入操作：

假设数组的长度为n，现在，如果我们需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要将第k~n这部分的元素都顺序地往后挪一位。

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是O(n)。因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为(1+2+...n)/n=O(n)。

#### 删除操作：

如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为O(1);如果删除开头的数据，则最坏情况时间复杂度为O(n);平均情况时间复杂度也为O(n)。

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢?

我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，**只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作**，这样就大大减少了删除操作导致的数据搬移。

如果你了解 JVM，你会发现，这不就是 JVM标记清除垃圾回收算法的核心思想吗?没错，数据结构和算法的魅力就在于此，**很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的**。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。

#### 数组访问越界问题：

数组越界在C语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。

这种情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。

但并非所有的语言都像C一样，把数组越界检查的工作丢给程序员来做，像Java本身就会做越界检查，越界就会抛出java.lang.ArrayIndexOutOfBoundsException。

#### **容器能否完全替代数组?**

针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢?

ArrayList 最大的优势就是**可以将很多数组操作的细节封装起来**。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是**支持动态扩容**。

数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的 空间，将原来的数据复制过去，然后再将新的数据插入。

如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。

不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以， 如果事先能确定需要存储的数据大小，最好**在创建 ArrayList 的时候事先指定数据大小**。

比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作。

```JAVA
ArrayList<User> users = new ArrayList(10000); 
for (int i = 0; i < 10000; ++i) {
    users.add(xxx);
}
```



作为高级语言编程者，是不是数组就无用武之地了呢?当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验。

1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。

2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。

3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[] [] array;而用容器的话则需要这样定义:ArrayList<ArrayList> array。

**对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。**



## 三、链表

经典的链表应用场景——就是 LRU 缓存淘汰算法。

缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比 如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。

缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留?这就需要缓存淘汰策略来决定。常见的策略有三种:先进先出策略 FIFO(First In，First Out)、最少使用策略 LFU(Least Frequently Used)、最近最少使用策略 LRU(Least Recently Used)。

**如何用链表来实现 LRU 缓存淘汰策略呢?**

数组与链表的区别：

#### 底层的存储结构：

- 数组：需要一块**连续的内存空间**，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够 大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。
- 链表：不需要连续的内存空间，它通过“指针”将一组**零散的内存块**串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。

![image-20221121205423921](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/数组与链表的内存空间分布.png)

链表的三种结构：单链表、双向链表、循环链表。

1. #### 单链表

![image-20221121210244496](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/单链表结构图.png)  

第一个结点叫作**头结点**，把最后一个结点叫作**尾结点**。

- 头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。

- 尾结点特殊的地方是:指针不是指向下一个结点，而是指向一个**空地址 NULL**，表示这是链表上最后一个结点。

在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。

![image-20221121210608733](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/链表的插入与删除操作.png)

针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。

链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。

2. #### 循环链表

	循环链表的尾结点指针是指向链表的头结点。

	![image-20221121211807876](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/循环链表结构图.png)

	**循环链表**的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。

3. #### 双向链表

	在实际的软件开发中，也更加常用的链表结构。双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前 驱指针 prev 指向前面的结点。
	
	![image-20221121211942444](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/双向链表结构图.png)
	
	双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。
	
	从结构上来看，双向链表可以支持 **O(1) 时间复杂度的情况下找到前驱结点**，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。
	
	##### **删除操作**
	
	> 删除结点中“值等于某个给定值”的结点;
		>
	> > 不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。
		> > 尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表。操作的总时间复杂度为 O(n)。h
		> 
		> 删除给定指针指向的结点。
		> 
		>> 我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。
		> >
		>> 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了!
	
	同理，如果我们希望在链表的某个指定结点前面**插入**一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。
	
	除了插入、删除操作有优势之外，对于一个**有序链表**，双向链表的**按值查询**的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。（二分查找）
	
	> 如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。



**用空间换时间**的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。

缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。
所以我总结一下，对于执行较慢的程序，可以通过消耗更多的内存(空间换时间)来进行优化;而消耗过多内存的程序，可以通过消耗更多的时间(时间换空间)来降低内存的消耗。

### 数组与链表的对比选择：

数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。

数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足(out of memory)”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与 数组最大的区别。

如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结 点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而 且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎 片，如果是 Java 语言，就有可能会导致频繁的 GC(Garbage Collection，垃圾回收)。

### 如何基于链表实现 LRU 缓存淘汰算法?

我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。
当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。

1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从 原来的位置删除，然后再插入到链表的头部。

2. 如果此数据没有在缓存链表中，又可以分为两种情况:

 如果此时缓存未满，则将此结点直接插入到链表的头部;
 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。





### 课后提问：


>如果字符串是通过**单链表**来存储的，那该如何来判断是一个回文串呢?你有什么好的解决思路呢?相应的时间空间复杂度又是多少呢?
>
>——LeetCode234. 回文链表

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public boolean isPalindrome(ListNode head) {
        if(head == null){
            return true;
        }
        ListNode firstHalfEnd = endOfFirstHalf(head);
        ListNode secondHalfStart = reverseList(firstHalfEnd.next);

        ListNode p1 = head;
        ListNode p2 = secondHalfStart;
        boolean result = true;
        // 比较前一半的值与反转后的后一半的值
        // 即头尾一一比较。
        while(result && p2 != null){
            if(p1.val != p2.val){
                result = false;
            }
            p1 = p1.next;
            p2 = p2.next;
        }

        firstHalfEnd.next = reverseList(secondHalfStart);
        return result;
    }

    public ListNode endOfFirstHalf(ListNode head){
        // 利用快慢指针寻找链表的中点
        ListNode fast = head;
        ListNode slow = head;
        while(fast.next!=null && fast.next.next!=null){
            fast = fast.next.next;
            slow = slow.next;
        }
        return slow;
    }

    public ListNode reverseList(ListNode head){
        // 反转链表
        ListNode prev = null;
        ListNode curr = head;
        while(curr!=null){
            ListNode nextTemp = curr.next;
            curr.next = prev;
            prev = curr;
            curr = nextTemp;
        }
        return prev;
    }
}
```





### **写链表代码技巧**

1. #### 理解指针或引用的含义

  要想写对链表代码，首先就要理解好**指针**。

> **将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。**

在编写链表代码的时候，我们经常会有这样的代码:`p->next=q`。这行代码是说，p 结点 中的 next 指针存储了 q 结点的内存地址。

还有一个更复杂的，也是我们写链表代码经常会用到的:`p->next=p->next->next`。这行 代码表示，p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址。


2. #### 警惕指针丢失和内存泄漏

	写链表代码的时候，指针指来指去，一会儿就不知道指到哪里了。所以，我们在写的时候，一定注意不要弄丢了指针。
	
	插入结点时注意操作的顺序。
	
	
	```java
	x.next=curr.next;
	curr.next = x;
	```
	
	
	删除链表节点时，也一定要记得手动释放内存空间，否则会出现内存泄漏的问题。当然，对于像 Java 这种虚拟机自动管理内存的编程语言来说，就不需要考虑这么多 了。
	
3. #### 利用哨兵简化实现难度

  **针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理**。

  head=null 表示链表中没有结点了。其中 head 表示头结 点指针，指向链表中的第一个结点。

  如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨 兵结点。我们也把这种有哨兵结点的链表叫**带头链表**。相反，没有哨兵结点的链表就叫作**不带头链表**。

  ![image-20221129213607809](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/带头链表.png)



  你可以发现，哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。

  实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、 归并排序、动态规划等。ik9,

4. #### 重点留意边界条件处理

	软件开发中，代码在一些**边界或者异常**情况下，最容易产生 Bug。链表代码也不例外。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下是否能正确运行。
	
	我经常用来检查链表代码是否正确的边界条件有这样几个:
		**如果链表为空时，代码是否能正常工作?**
		**如果链表只包含一个结点时，代码是否能正常工作?**
		**如果链表只包含两个结点时，代码是否能正常工作?**
		**代码逻辑在处理头结点和尾结点的时候，是否能正常工作?**
	当你写完链表代码之后，除了看下你写的代码在正常的情况下能否工作，还要看下在上面我列举的几个边界条件下，代码仍然能否正确工作。如果这些边界条件下都没有问题，那基本上可以认为没有问题了。
	
	当然，边界条件不止我列举的那些。针对不同的场景，可能还有特定的边界条件，这个需要你自己去思考，不过套路都是一样的。
	
	实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮!
		
	
5. #### 举例画图，辅助思考

	对于稍微复杂的链表操作，比如前面我们提到的单链表反转，指针一会儿指这，一会儿指那，一会儿就被绕晕了。总感觉脑容量不够，想不清楚。所以这个时候就要使用大招了，**举例法**和**画图法**。

	![image-20221129214917616](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/不同情况下的链表的插入.png)

6. #### 多写多练，没有捷径

	我精选了 5 个常见的链表操作。你只要把这几个操作都能写熟练，不熟就多写几遍，我保证你之后再也不会害怕写链表代码。

	单链表反转——LeetCode206

	链表中环的检测——LeetCode141

	两个有序的链表合并——LeetCode21

	删除链表倒数第 n 个结点——LeetCode19

	求链表的中间结点——LeetCode876



**写链表代码是最考验逻辑思维能力的**。因为，链表代码到处都是指针的操作、边界 条件的处理，稍有不慎就容易产生 Bug。链表代码写得好坏，可以看出一个人写代码是否 够细心，考虑问题是否全面，思维是否缜密。所以，这也是很多面试官喜欢让人手写链表代码的原因。





## 四、栈

#### **后进者先出，先进者后出，这就是典型的“栈”结构。**

从栈的操作特性上来看，**栈是一种“操作受限”的线性表**，只允许在一端插入和删除数据。

```
从功能上来说，数组或链表确实可以替代栈，但你要知道，特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。
```

**当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们 就应该首选“栈”这种数据结构**。

### 如何实现栈？

从栈的定义里可以看出，栈主要包含了两种操作，**入栈和出栈**，也就是在栈顶插入一个数据和从栈顶删除一个数据。

实际上，栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作**顺序栈**，用链表实现的栈，我们叫作**链式栈**。不管是顺序栈还是链式栈，我们存储数据只需要一个大小为 n 的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是 O(1)。

注意，这里存储数据需要一个大小为 n 的数组，并不是说空间复杂度就是 O(n)。因为，这 n 个空间是必须的，无法省掉。所以我们说空间复杂度的时候，是指除了原本的数据存储、间外，算法运行还需要额外的存储空间。

空间复杂度分析是不是很简单?时间复杂度也不难。不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)。

```java
// 基于数组实现的顺序栈

```



### 栈在函数调用中的应用

栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中，比较经典的一个应用场景就是**函数调用栈**。

**操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。**

![img](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/函数调用栈.png)

### 栈在表达式求值中的应用

将算术表达式简化为只包含加减乘除四则运算，比如：34+13*9+44-12/3。对于这个四则运算，我们人脑可以很快求解出答案，但是对于计算机来说，理解这个表达式本身就是个挺难的事儿。

实际上，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。

如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

![image-20221206212712093](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/表达式求值应用栈.png)

### 栈在括号匹配中的应用

除了用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。

我们同样简化一下背景。我们假设表达式中只包含三种括号，圆括号 ()、方括号 [] 和花括号{}，并且它们可以任意嵌套。比如，{[{}]}或 [{()}([])] 等都为合法格式，而{[}()] 或 [({)] 为不合法的格式。那我现在给你一个包含三种括号的表达式字符串，如何检查它是否合法呢？

这里也可以用栈来解决。**我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。**

**当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。**

### 如何实现浏览器的前进、后退功能

X 和 Y，我们把首次浏览的页面依次压入栈 X，当点击后退按钮时，再依次从栈 X 中出栈，并将出栈的数据依次放入栈 Y。当我们点击前进按钮时，我们依次从栈 Y 中取出数据，放入栈 X 中。当栈 X 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。

比如你顺序查看了 a，b，c 三个页面，我们就依次把 a，b，c 压入栈，这个时候，两个栈的数据就是这个样子：

![浏览器的前进后退0](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/浏览器的前进后退0.png)

当你通过浏览器的后退按钮，从页面 c 后退到页面 a 之后，我们就依次把 c 和 b 从栈 X 中弹出，并且依次放入到栈 Y。这个时候，两个栈的数据就是这个样子：

![img](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/浏览器的前进后退1.png)

这个时候你又想看页面 b，于是你又点击前进按钮回到 b 页面，我们就把 b 再从栈 Y 中出栈，放入栈 X 中。此时两个栈的数据是这个样子：

![img](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/浏览器的前进后退2.png)

这个时候，你通过页面 b 又跳转到新的页面 d 了，页面 c 就无法再通过前进、后退按钮重复查看了，所以需要清空栈 Y。此时两个栈的数据这个样子：

![img](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/浏览器的前进后退3.png)



## 五、队列

### 开篇引入

#### CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的。

#### **当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？**

#### 实际上，这些问题并不复杂，其底层的数据结构就是我们今天要学的内容，队列（queue）。

### 如何理解队列？

**先进者先出，这就是典型的“队列”**。

**入队 enqueue()**，放一个数据到队列尾部；**出队 dequeue()**，从队列头部取一个元素。

![image-20221206215535463](/Users/ouusen/Documents/LearningAlgorithm/01-数据结构与算法之美（完结）/pics/队列与栈.png)